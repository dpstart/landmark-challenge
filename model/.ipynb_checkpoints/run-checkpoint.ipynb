{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images belonging to 2 classes.\n",
      "{'1': 0, '2': 1}\n",
      "2\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 604s - loss: 0.0321 - acc: 0.9870   \n",
      "Epoch 2/3\n",
      " 581/3000 [====>.........................] - ETA: 474s - loss: 7.6171e-04 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "\n",
    "MODEL_DIR = './models/'\n",
    "TRAIN_IMAGE_DIR = './data/'\n",
    "\n",
    "# VALIDATION_IMAGE_DIR = \"./val/\"\n",
    "\n",
    "(img_width, img_height) = (128, 128)\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "def print_duration(start_time, msg):\n",
    "    print('[%d] %s' % (int(time.time() - start_time), msg))\n",
    "    start_time = time.time()\n",
    "    return start_time\n",
    "\n",
    "\n",
    "def train():\n",
    "    if os.path.isdir(TRAIN_IMAGE_DIR):\n",
    "\n",
    "        train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "        #val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "        train_generator = \\\n",
    "            train_datagen.flow_from_directory(TRAIN_IMAGE_DIR,\n",
    "                target_size=(img_width, img_height),\n",
    "                batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "        total_val_image_count = train_generator.samples\n",
    "        print(train_generator.class_indices)\n",
    "        nr_of_classes = len(train_generator.class_indices)\n",
    "        print(nr_of_classes)\n",
    "\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(120, (3, 3), input_shape=input_shape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(80, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(80, (3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(65))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nr_of_classes))\n",
    "        model.add(Activation('sigmoid'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='sgd',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # 'steps_per_epoch: Total number of steps (batches of samples) to yield from generator before declaring one\n",
    "        # epoch finished and starting the next epoch.\n",
    "        # It should typically be equal to the number of unique samples of your dataset divided by the batch size.\n",
    "\n",
    "        model.fit_generator(train_generator, epochs=3,\n",
    "                            steps_per_epoch=300)\n",
    "        model.save(MODEL_DIR + 'model.h5')\n",
    "        \n",
    "        #img = image.load_img('./data/1/colosseo.jpg', target_size=(128, 128))\n",
    "        \n",
    "        img = cv2.resize(cv2.imread('./data/1/colosseo.jpg'), (128, 128))\n",
    "        img = img.astype(np.float32, copy=False)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        print(model.predict(img))\n",
    "    else:\n",
    "\n",
    "        print('Training set not found!')\n",
    "\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "\n",
    "    train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
